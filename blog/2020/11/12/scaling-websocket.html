<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9e615eff0">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Centrifugo Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Centrifugo Blog Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-204787498-1","auto"),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script><title data-react-helmet="true">Scaling WebSocket in Go and beyond | Centrifugo</title><meta data-react-helmet="true" property="og:title" content="Scaling WebSocket in Go and beyond | Centrifugo"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="description" content="Scaling WebSocket in Go and beyond"><meta data-react-helmet="true" property="og:description" content="Scaling WebSocket in Go and beyond"><meta data-react-helmet="true" property="og:url" content="https://centrifugal.dev/blog/2020/11/12/scaling-websocket"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:image" content="https://i.imgur.com/QOJ1M9a.png"><meta data-react-helmet="true" name="twitter:image" content="https://i.imgur.com/QOJ1M9a.png"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.png"><link data-react-helmet="true" rel="canonical" href="https://centrifugal.dev/blog/2020/11/12/scaling-websocket"><link data-react-helmet="true" rel="alternate" href="https://centrifugal.dev/blog/2020/11/12/scaling-websocket" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://centrifugal.dev/blog/2020/11/12/scaling-websocket" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.3bbeba6c.css">
<link rel="preload" href="/assets/js/runtime~main.55faadf6.js" as="script">
<link rel="preload" href="/assets/js/main.b54f4b3e.js" as="script">
</head>
<body>
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_2qcr"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><img src="/img/logo.svg" alt="Centrifugo Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/img/logo.svg" alt="Centrifugo Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">Centrifugo</b></a><a class="navbar__item navbar__link" href="/docs/getting-started/introduction">Getting Started</a><a class="navbar__item navbar__link" href="/docs/server/configuration">Server guide</a><a class="navbar__item navbar__link" href="/docs/transports/overview">Transports</a><a class="navbar__item navbar__link" href="/docs/ecosystem/client">Ecosystem</a><a class="navbar__item navbar__link" href="/docs/pro/overview">Centrifugo PRO</a><a class="navbar__item navbar__link" href="/docs/faq/index">FAQ</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/centrifugal/centrifugo" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="react-toggle toggle_3Zt9 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_MM2z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_s5VG searchBarLoadingRing_2jQk"><div></div><div></div><div></div><div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_2ahu thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_2hhb margin-bottom--md">All our posts</div><ul class="sidebarItemList_2xAf"><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/2021/11/04/integrating-with-django-building-chat-application">Centrifugo integration with Django â€“ building a basic chat application</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/2021/10/18/integrating-with-nodejs">Centrifugo integration with NodeJS tutorial</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/2021/08/31/hello-centrifugo-v3">Centrifugo v3 released</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/2021/01/15/centrifuge-intro">Centrifuge â€“ real-time messaging with Go</a></li><li class="sidebarItem_2UVv"><a aria-current="page" class="sidebarItemLink_1RT6 sidebarItemLinkActive_12pM" href="/blog/2020/11/12/scaling-websocket">Scaling WebSocket in Go and beyond</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/2020/10/16/experimenting-with-quic-transport">Experimenting with QUIC and WebTransport</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/2020/02/10/million-connections-with-centrifugo">Million connections with Centrifugo</a></li></ul></nav></aside><main class="col col--7"><article><header><h1 class="blogPostTitle_GeHD">Scaling WebSocket in Go and beyond</h1><div class="blogPostData_291c margin-vert--md"><time datetime="2020-11-12T00:00:00.000Z">November 12, 2020</time> Â· 19 min read</div><div class="avatar margin-vert--md"><a class="avatar__photo-link avatar__photo"><img src="https://github.com/FZambia.png" alt="Alexander Emelin"></a><div class="avatar__intro"><div class="avatar__name"><a>Alexander Emelin</a></div><small class="avatar__subtitle">Creator of Centrifugo</small></div></div></header><div class="markdown"><p><img src="https://i.imgur.com/QOJ1M9a.png" alt="gopher-broker"></p><p>I believe that in 2020 WebSocket is still an entertaining technology which is not so well-known and understood like HTTP. In this blog post I&#x27;d like to tell about state of WebSocket in Go language ecosystem, and a way we could write scalable WebSocket servers with Go and beyond Go.</p><p>We won&#x27;t talk a lot about WebSocket transport pros and cons â€“ I&#x27;ll provide links to other resources on this topic. Most advices here are generic enough and can be easily approximated to other programming languages. Also in this post we won&#x27;t talk about ready to use solutions (if you are looking for it â€“ check out <a href="https://www.leggetter.co.uk/real-time-web-technologies-guide/" target="_blank" rel="noopener noreferrer">Real-time Web Technologies guide</a> by Phil Leggetter), just general considerations. There is not so much information about scaling WebSocket on the internet so if you are interested in WebSocket and real-time messaging technologies - keep on reading.</p><p>If you don&#x27;t know what WebSocket is â€“ check out the following curious links:</p><ul><li><a href="https://hpbn.co/websocket/" target="_blank" rel="noopener noreferrer">https://hpbn.co/websocket/</a> â€“ a wonderful chapter of great book by Ilya Grigorik</li><li><a href="https://lucumr.pocoo.org/2012/9/24/websockets-101/" target="_blank" rel="noopener noreferrer">https://lucumr.pocoo.org/2012/9/24/websockets-101/</a> â€“ valuable thoughts about WebSocket from Armin Ronacher</li></ul><p>As soon as you know WebSocket basics â€“ we can proceed.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="websocket-server-tasks"></a>WebSocket server tasks<a class="hash-link" href="#websocket-server-tasks" title="Direct link to heading">#</a></h2><p>Speaking about scalable servers that work with many persistent WebSocket connections â€“ I found several important tasks such a server should be able to do:</p><ul><li>Maintain many active connections</li><li>Send many messages to clients</li><li>Support WebSocket fallback to scale to every client</li><li>Authenticate incoming connections and invalidate connections</li><li>Survive massive reconnect of all clients without loosing messages</li></ul><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></div><div class="admonition-content"><p>Of course not all of these points equally important in various situations.</p></div></div><p>Below we will look at some tips which relate to these points.</p><p><img src="https://i.imgur.com/4lYjJSP.png" alt="one_hour_scale"></p><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="websocket-libraries"></a>WebSocket libraries<a class="hash-link" href="#websocket-libraries" title="Direct link to heading">#</a></h2><p>In Go language ecosystem we have several libraries which can be used as a building block for a WebSocket server.</p><p>Package <a href="https://godoc.org/golang.org/x/net/websocket" target="_blank" rel="noopener noreferrer">golang.org/x/net/websocket</a> is considered <strong>deprecated</strong>.</p><p>The default choice in the community is <a href="https://github.com/gorilla/websocket" target="_blank" rel="noopener noreferrer">gorilla/websocket</a> library. Made by Gary Burd (who also gifted us an awesome <a href="https://github.com/gomodule/redigo" target="_blank" rel="noopener noreferrer">Redigo</a> package to communicate with Redis) â€“ it&#x27;s widely used, performs well, has a very good API â€“ so in most cases you should go with it. Some people think that library not actively maintained at moment â€“ but this is not quite true, it implements full WebSocket RFC, so actually it can be considered done.</p><p>In 2018 my ex-colleague Sergey Kamardin open-sourced <a href="https://github.com/gobwas/ws" target="_blank" rel="noopener noreferrer">gobwas/ws</a> library. It provides a bit lower-level API than <code>gorilla/websocket</code> thus allows reducing RAM usage per connection and has nice optimizations for WebSocket upgrade process. It does not support WebSocket <code>permessage-deflate</code> compression but otherwise a good alternative you can consider using. If you have not read Sergey&#x27;s famous post <a href="https://www.freecodecamp.org/news/million-websockets-and-go-cc58418460bb/" target="_blank" rel="noopener noreferrer">A Million WebSockets and Go</a> â€“ make a bookmark!</p><p>One more library is <a href="https://github.com/nhooyr/websocket" target="_blank" rel="noopener noreferrer">nhooyr/websocket</a>. It&#x27;s the youngest one and actively maintained. It compiles to WASM which can be a cool thing for someone. The API is a bit different from what <code>gorilla/websocket</code> offers, and one of the big advantages I see is that it solves a problem with a proper WebSocket closing handshake which is <a href="https://github.com/gorilla/websocket/issues/448" target="_blank" rel="noopener noreferrer">a bit hard to do right with Gorilla WebSocket</a>.</p><p>You can consider all listed libraries except one from <code>x/net</code> for your project. Take a library, follow its examples (make attention to goroutine-safety of various API operations). Personally I prefer Gorilla WebSocket at moment since it&#x27;s feature-complete and battle tested by tons of projects around Go world.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="os-tuning"></a>OS tuning<a class="hash-link" href="#os-tuning" title="Direct link to heading">#</a></h2><p>OK, so you have chosen a library and built a server on top of it. As soon as you put it in production the interesting things start happening.</p><p>Let&#x27;s start with several OS specific key things you should do to prepare for many connections from WebSocket clients.</p><p>Every connection will cost you an open file descriptor, so you should tune a maximum number of open file descriptors your process can use. An errors like <code>too many open files</code> raise due to OS limit on file descriptors which is usually 256-1024 by default (see with <code>ulimit -n</code> on Unix). A nice overview on how to do this on different systems can be found <a href="https://docs.riak.com/riak/kv/2.2.3/using/performance/open-files-limit.1.html" target="_blank" rel="noopener noreferrer">in Riak docs</a>. Wanna more connections? Make this limit higher.</p><p>Nice tip here is to limit a maximum number of connections your process can serve â€“ making it less than known file descriptor limit:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly go"><pre tabindex="0" class="prism-code language-go codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic">//Â ulimitÂ -nÂ ==Â 65535</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">if</span><span class="token plain"> conns</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token function" style="color:rgb(130, 170, 255)">Len</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">&gt;=</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">65500</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token keyword" style="font-style:italic">return</span><span class="token plain"> errors</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token function" style="color:rgb(130, 170, 255)">New</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;connectionÂ limitÂ reached&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">conns</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token function" style="color:rgb(130, 170, 255)">Add</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">conn</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>â€“ otherwise you have a risk to not even able to look at <code>pprof</code> when things go bad. And you always need monitoring of open file descriptors.</p><p>You can also consider using <a href="https://godoc.org/golang.org/x/net/netutil#LimitListener" target="_blank" rel="noopener noreferrer">netutil.LimitListener</a> for this task, but don&#x27;t forget to put pprof on another port with another HTTP server instance in this case.</p><p>Keep attention on <em>Ephemeral ports</em> problem which is often happens between your load balancer and your WebSocket server. The problem arises due to the fact that each TCP connection uniquely identified in the OS by the 4-part-tuple:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">source ip | source port | destination ip | destination port</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>On balancer/server boundary you are limited in 65536 possible variants by default. But actually due to some OS limits and sockets in TIME_WAIT state the number is even less. A very good explanation and how to deal with it can be found <a href="https://making.pusher.com/ephemeral-port-exhaustion-and-how-to-avoid-it/" target="_blank" rel="noopener noreferrer">in Pusher blog</a>.</p><p>Your possible number of connections also limited by conntrack table. Netfilter framework which is part of iptables keeps information about all connections and has limited size for this information. See how to see its limits and instructions to increase <a href="https://morganwu277.github.io/2018/05/26/Solve-production-issue-of-nf-conntrack-table-full-dropping-packet/" target="_blank" rel="noopener noreferrer">in this article</a>.</p><p>One more thing you can do is tune your network stack for performance. Do this only if you understand that you need it. Maybe start <a href="https://gist.github.com/mustafaturan/47268d8ad6d56cadda357e4c438f51ca" target="_blank" rel="noopener noreferrer">with this gist</a>, but don&#x27;t optimize without full understanding why you are doing this. </p><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="sending-many-messages"></a>Sending many messages<a class="hash-link" href="#sending-many-messages" title="Direct link to heading">#</a></h2><p>Now let&#x27;s speak about sending many messages. The general tips follows.</p><p><strong>Make payload smaller</strong>. This is obvious â€“ fewer data means more effective work on all layers. BTW WebSocket framing overhead is minimal and adds only 2-8 bytes to your payload. You can read detailed dedicated research in <a href="https://crossbario.com/blog/Dissecting-Websocket-Overhead/" target="_blank" rel="noopener noreferrer">Dissecting WebSocket&#x27;s Overhead</a> article. You can reduce an amount of data traveling over network with <code>permessage-deflate</code> WebSocket extension, so your data will be compressed. Though using <code>permessage-deflate</code> is not always a good thing for server due to <a href="https://github.com/gorilla/websocket/issues/203" target="_blank" rel="noopener noreferrer">poor performance of flate</a>, so you should be prepared for a CPU and RAM resource usage on server side. While Gorilla WebSocket has a lot of optimizations internally by reusing flate writers, overhead is still noticeable. The increase value heavily depends on your load profile.</p><p><strong>Make less system calls</strong>. Every syscall will have a constant overhead, and actually in WebSocket server under load you will mostly see read and write system calls in your CPU profiles. An advice here â€“ try to use client-server protocol that supports message batching, so you can join individual messages together.</p><p><strong>Use effective message serialization protocol</strong>. Maybe use code generation for JSON to avoid extensive usage of reflect package done by Go std lib. Maybe use sth like <a href="https://github.com/gogo/protobuf" target="_blank" rel="noopener noreferrer">gogo/protobuf</a> package which allows to speedup Protobuf marshalling and unmarshalling. Unfortunately Gogo Protobuf <a href="https://github.com/gogo/protobuf/issues/691" target="_blank" rel="noopener noreferrer">is going through hard times
</a> at this moment. Try to serialize a message only once when sending to many subscribers.</p><p><strong>Have a way to scale to several machines</strong> - more power, more possible messages. We will talk about this very soon.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="websocket-fallback-transport"></a>WebSocket fallback transport<a class="hash-link" href="#websocket-fallback-transport" title="Direct link to heading">#</a></h2><p><img src="https://i.imgur.com/IAOyvmg.png" alt="ie"></p><p>Even in 2020 there are still users which cannot establish connection with WebSocket server. Actually the problem mostly appears with browsers. Some users still use old browsers. But they have a choice â€“ install a newer browser. Still, there could also be users behind corporate proxies. Employees can have a trusted certificate installed on their machine so company proxy can re-encrypt even TLS traffic. Also, some browser extensions can block WebSocket traffic.</p><p>One ready solution to this is <a href="https://github.com/igm/sockjs-go/" target="_blank" rel="noopener noreferrer">Sockjs-Go</a> library. This is a mature library that provides fallback transport for WebSocket. If client does not succeed with WebSocket connection establishment then client can use some of HTTP transports for client-server communication: <a href="https://hpbn.co/server-sent-events-sse/" target="_blank" rel="noopener noreferrer">EventSource aka Server-Sent Events</a>, XHR-streaming, Long-Polling etc. The downside with those transports is that to achieve bidirectional communication you should use sticky sessions on your load balancer since SockJS keeps connection session state in process memory. We will talk about many instances of your WebSocket server very soon.</p><p>You can implement WebSocket fallback yourself, this should be simple if you have a sliding window message stream on your backend which we will discuss very soon.</p><p>Maybe look at <a href="https://grpc.io/docs/what-is-grpc/introduction/" target="_blank" rel="noopener noreferrer">GRPC</a>, depending on application it could be better or worse than WebSocket â€“ in general you can expect a better performance and less resource consumption from WebSocket for bidirectional communication case. My measurements for a <strong>bidirectional</strong> scenario showed 3x win for WebSocket (binary + GOGO protobuf) in terms of server CPU consumption and 4 times less RAM per connection. Though if you only need RPC then GRPC can be a better choice. But you need additional proxy to work with GRPC from a browser. </p><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="performance-is-not-scalability"></a>Performance is not scalability<a class="hash-link" href="#performance-is-not-scalability" title="Direct link to heading">#</a></h2><p>You can optimize client-server protocol, tune your OS, but at some point you won&#x27;t be able to use only one process on one server machine. You need to scale connections and work your server does over different server machines. Horizontal scaling is also good for a server high availability. Actually there are some sort of real-time applications where a single isolated process makes sense - for example multiplayer games where limited number of players play independent game rounds.</p><p><img src="https://i.imgur.com/8ElqpjI.png" alt="many_instances"></p><p>As soon as you distribute connections over several machines you have to find a way to deliver a message to a certain user. The basic approach here is to publish messages to all server instances. This can work but this does not scale well. You need a sort of instance discovery to make this less painful.</p><p>Here comes PUB/SUB, where you can connect WebSocket server instances over central PUB/SUB broker. Clients that establish connections with your WebSocket server subscribe to topics (channels) in a broker, and as soon as you publish a message to that topic it will be delivered to all active subscribers on WebSocket server instances. If server node does not have interested subscriber then it won&#x27;t get a message from a broker thus you are getting effective network communication.</p><p>Actually the main picture of this post illustrates exactly this architecture:</p><p><img src="https://i.imgur.com/QOJ1M9a.png" alt="gopher-broker"></p><p>Let&#x27;s think about requirements for a broker for real-time messaging application. We want a broker:</p><ul><li>with reasonable performance and possibility to scale</li><li>which maintains message order in topics</li><li>can support millions of topics, where each topic should be ephemeral and lightweight â€“ topics can be created when user comes to application and removed after user goes away</li><li>possibility to keep a sliding window of messages inside channel to help us survive massive reconnect scenario (will talk about this later below, can be a separate part from broker actually)</li></ul><p>Personally when we talk about such brokers here are some options that come into my mind:</p><ul><li><a href="https://www.rabbitmq.com/" target="_blank" rel="noopener noreferrer">RabbitMQ</a></li><li><a href="https://kafka.apache.org/" target="_blank" rel="noopener noreferrer">Kafka</a> or <a href="https://pulsar.apache.org/" target="_blank" rel="noopener noreferrer">Pulsar</a></li><li><a href="https://nats.io/" target="_blank" rel="noopener noreferrer">Nats or Nats-Streaming</a></li><li><a href="https://www.tarantool.io/en/" target="_blank" rel="noopener noreferrer">Tarantool</a></li><li><a href="https://redis.io/" target="_blank" rel="noopener noreferrer">Redis</a></li></ul><p><strong>Sure there are more exist</strong> including libraries like <a href="https://zeromq.org/" target="_blank" rel="noopener noreferrer">ZeroMQ</a> or <a href="https://nanomsg.org/" target="_blank" rel="noopener noreferrer">nanomsg</a>.</p><p>Below I&#x27;ll try to consider these solutions for the task of making scalable WebSocket server facing many user connections from Internet.</p><p>If you are looking for unreliable at most once PUB/SUB then any of solutions mentioned above should be sufficient. Many real-time messaging apps are ok with at most once guarantee delivery.</p><p>If you don&#x27;t want to miss messages then things are a bit harder. Let&#x27;s try to evaluate these options for a task where application has lots of different topics from which it wants to receive messages with at least once guarantee (having a personal topic per client is common thing in applications). A short analysis below can be a bit biased, but I believe thoughts are reasonable enough. I did not found enough information on the internet about scaling WebSocket beyond a single server process, so I&#x27;ll try to fill the gap a little based on my personal knowledge without pretending to be absolutely objective in these considerations.</p><p>In some posts on the internet about scaling WebSocket I saw advices to use RabbitMQ for PUB/SUB stuff in real-time messaging server. While this is a great messaging server, it does not like a high rate of queue bind and unbind type of load. It will work, but you will need to use a lot of server resources for not so big number of clients (imagine having millions of queues inside RabbitMQ). I have an example from my practice where RabbitMQ consumed about 70 CPU cores to serve real-time messages for 100k online connections. After replacing it with Redis keeping the same message delivery semantics we got only 0.3 CPU consumption on broker side.</p><p>Kafka and Pulsar are great solutions, but not for this task I believe. The problem is again in dynamic ephemeral nature of our topics. Kafka also likes a more stable configuration of its topics. Keeping messages on disk can be an overkill for real-time messaging task. Also your consumers on Kafka server should pull from millions of different topics, not sure how well it performs, but my thoughts at moment - this should not perform very well. Kafka itself scales perfectly, you will definitely be able to achieve a goal but resource usage will be significant. Here is <a href="https://tech.trello.com/why-we-chose-kafka/" target="_blank" rel="noopener noreferrer">a post from Trello</a> where they moved from RabbitMQ to Kafka for similar real-time messaging task and got about 5x resource usage improvements. Note also that the more partitions you have the more heavy failover process you get.</p><p>Nats and Nats-Streaming. Raw Nats can only provide at most once guarantee. BTW recently Nats developers <a href="https://github.com/nats-io/nats-server/issues/315" target="_blank" rel="noopener noreferrer">released native WebSocket support</a>, so you can consider it for your application. Nats-Streaming server as broker will allow you to not lose messages. To be fair I don&#x27;t have enough information about how well Nats-Streaming scales to millions of topics. An upcoming <a href="https://github.com/nats-io/jetstream" target="_blank" rel="noopener noreferrer">Jetstream</a> which will be a part of Nats server can also be an interesting option â€“ like Kafka it provides a persistent stream of messages for at least once delivery semantics. But again, it involves disk storage, a nice thing for backend microservices communication but can be an overkill for real-time messaging task.</p><p>Sure Tarantool can fit to this task well too. It&#x27;s fast, im-memory and flexible. Some possible problems with Tarantool are not so healthy state of its client libraries, complexity and the fact that it&#x27;s heavily enterprise-oriented. You should invest enough time to benefit from it, but this can worth it actually. See <a href="https://hackernoon.com/tarantool-when-it-takes-500-lines-of-code-to-notify-a-million-users-11d340523493" target="_blank" rel="noopener noreferrer">an article</a> on how to do a performant broker for WebSocket applications with Tarantool.</p><p>Building PUB/SUB system on top of ZeroMQ will require you to build separate broker yourself. This could be an unnecessary complexity for your system. It&#x27;s possible to implement PUB/SUB pattern with ZeroMQ and nanomsg without a central broker, but in this case messages without active subscribers on a server will be dropped on a consumer side thus all publications will travel to all server nodes. </p><p>My personal choice at moment is Redis. While <strong>Redis PUB/SUB itself provides at most once guarantee</strong>, you can build at least once delivery on top of PUB/SUB and Redis data structures (though this can be challenging enough). Redis is very fast (especially when using pipelining protocol feature), and what is more important â€“ <strong>very predictable</strong>. It gives you a good understanding of operation time complexity. You can shard topics over different Redis instances running in HA setup - with Sentinel or with Redis Cluster. It allows writing LUA procedures with some advanced logic which can be uploaded over client protocol thus feels like ordinary commands. You can use Redis to keep sliding window event stream which gives you access to missed messages from a certain position. We will talk about this later.</p><p>OK, the end of opinionated thoughts here :)</p><p>Depending on your choice the implementation of your system will vary and will have different properties â€“ so try to evaluate possible solutions based on your application requirements. Anyway, whatever broker will be your choice, try to follow this rules to build effective PUB/SUB system:</p><ul><li>take into account message delivery guarantees of your system: at most once or at least once, ideally you should have an option to have both for different real-time features in your app</li><li>make sure to use one or pool of connections between your server and a broker, don&#x27;t create new connection per each client or topic that comes to your WebSocket server</li><li>use effective serialization format between your WebSocket server and broker</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="massive-reconnect"></a>Massive reconnect<a class="hash-link" href="#massive-reconnect" title="Direct link to heading">#</a></h2><p><img src="https://i.imgur.com/S9koKYg.png" alt="mass_reconnect"></p><p>Let&#x27;s talk about one more problem that is unique for Websocket servers compared to HTTP. Your app can have thousands or millions of active WebSocket connections. In contract to stateless HTTP APIs your application is stateful. It uses push model. As soon as you deploying your WebSocket server or reload your load balancer (Nginx maybe) â€“ connections got dropped and all that army of users start reconnecting. And this can be like an avalanche actually. How to survive?</p><p>First of all - use exponential backoff strategies on client side. I.e. reconnect with intervals like 1, 2, 4, 8, 16 seconds with some random jitter.</p><p>Turn on various rate limiting strategies on your WebSocket server, some of them should be turned on your backend load balancer level (like controlling TCP connection establishment rate), some are application specific (maybe limit an amount of requests from certain user).</p><p>One more interesting technique to survive massive reconnect is using JWT (JSON Web Token) for authentication. I&#x27;ll try to explain why this can be useful.</p><p><img src="https://i.imgur.com/aaTEhXo.png" alt="jwt"></p><p>As soon as your client start reconnecting you will have to authenticate each connection. In massive setups with many persistent connection this can be a very significant load on your Session backend. Since you need an extra request to your session storage for every client coming back. This can be a no problem for some infrastructures but can be really disastrous for others. JWT allows to reduce this spike in load on session storage since it can have all required authentication information inside its payload. When using JWT make sure you have chosen a reasonable JWT expiration time â€“ expiration interval depends on your application nature and just one of trade-offs you should deal with as developer.</p><p>Don&#x27;t forget about making an effective connection between your WebSocket server and broker â€“ as soon as all clients start reconnecting you should resubscribe your server nodes to all topics as fast as possible. Use techniques like smart batching at this moment.</p><p>Let&#x27;s look at a small piece of code that demonstrates this technique. Imagine we have a source channel from which we get items to process. We donâ€™t want to process items individually but in batch. For this we wait for first item coming from channel, then try to collect as many items from channel buffer as we want without blocking and timeouts involved. And then process slice of items we collected at once. For example build Redis pipeline from them and send to Redis in one connection write call.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly go"><pre tabindex="0" class="prism-code language-go codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">maxBatchSize </span><span class="token operator" style="color:rgb(137, 221, 255)">:=</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">50</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">for</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token keyword" style="font-style:italic">select</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token keyword" style="font-style:italic">case</span><span class="token plain"> item </span><span class="token operator" style="color:rgb(137, 221, 255)">:=</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">&lt;-</span><span class="token plain">sourceCh</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        batch </span><span class="token operator" style="color:rgb(137, 221, 255)">:=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token builtin" style="color:rgb(130, 170, 255)">string</span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain">item</span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    loop</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token keyword" style="font-style:italic">for</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">len</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">batch</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">&lt;</span><span class="token plain"> maxBatchSize </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            </span><span class="token keyword" style="font-style:italic">select</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            </span><span class="token keyword" style="font-style:italic">case</span><span class="token plain"> item </span><span class="token operator" style="color:rgb(137, 221, 255)">:=</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">&lt;-</span><span class="token plain">sourceCh</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                batch </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">append</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">batch</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> item</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            </span><span class="token keyword" style="font-style:italic">default</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                </span><span class="token keyword" style="font-style:italic">break</span><span class="token plain"> loop</span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic">// Do sth with collected batch of items.</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token function" style="color:rgb(130, 170, 255)">println</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token function" style="color:rgb(130, 170, 255)">len</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">batch</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token plain"></span></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Look at a complete example in a Go playground: <a href="https://play.golang.org/p/u7SAGOLmDke" target="_blank" rel="noopener noreferrer">https://play.golang.org/p/u7SAGOLmDke</a>.</p><p>I also made a repo where I demonstrate how this technique together with Redis pipelining feature allows to fully utilize connection for a good performance <a href="https://github.com/FZambia/redigo-smart-batching" target="_blank" rel="noopener noreferrer">https://github.com/FZambia/redigo-smart-batching</a>.</p><p>Another advice for those who run WebSocket services in Kubernetes. Learn how your ingress behaves â€“ for example Nginx ingress can reload its configuration on every change inside Kubernetes services map resulting into closing all active WebSocket connections. Proxies like Envoy don&#x27;t have this behaviour, so you can reduce number of mass disconnections in your system. You can also proxy WebSocket without using ingress at all over configured WebSocket service NodePort.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="message-event-stream-benefits"></a>Message event stream benefits<a class="hash-link" href="#message-event-stream-benefits" title="Direct link to heading">#</a></h2><p>Here comes a final part of this post. Maybe the most important one.</p><p>Not only mass client re-connections could create a significant load on a session backend but also a huge load on your main application database. Why? Because WebSocket applications are stateful. Clients rely on a stream of messages coming from a backend to maintain its state actual. As soon as connection dropped client tries to reconnect. In some scenarios it also wants to restore its actual state. What if client reconnected after 3 seconds? How many state updates it could miss? Nobody knows. So to make sure state is actual client tries to get it from application database. This is again <strong>a significant spike in load on your main database</strong> in massive reconnect scenario. In can be really painful with many active connections.</p><p>So what I think is nice to have for scenarios where we can&#x27;t afford to miss messages (like in chat-like apps for example) is having effective and performant stream of messages inside each channel. Keep this stream in fast in-memory storage. This stream can have time retention and be limited in size (think about it as a sliding window of messages). I already mentioned that Redis can do this â€“ it&#x27;s possible to keep messages in Redis List or Redis Stream data structures. Other broker solutions could give you access to such a stream inside each channel out of the box.</p><p>So as soon as client reconnects it can restore its state from fast in-memory event stream without even querying your database. Actually to survive mass reconnect scenario you don&#x27;t need to keep such a stream for a long time â€“ several minutes should be enough. You can <strong>even create your own Websocket fallback implementation (like Long-Polling) utilizing event stream with limited retention</strong>.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor" id="conclusion"></a>Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">#</a></h2><p>Hope advices given here will be useful for a reader and will help writing a more robust and more scalable real-time application backends.</p><p><a href="https://github.com/centrifugal/centrifugo/" target="_blank" rel="noopener noreferrer">Centrifugo server</a> and <a href="https://github.com/centrifugal/centrifuge" target="_blank" rel="noopener noreferrer">Centrifuge library for Go language</a> have most of the mechanics described here including the last one â€“ message stream for topics limited by size and retention period. Both also have techniques to prevent message loss due to at most once nature of Redis PUB/SUB giving at least once delivery guarantee inside message history window size and retention period.</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_3kfx"><div class="col"><b>Tags:</b><a class="margin-horiz--sm" href="/blog/tags/websocket">websocket</a><a class="margin-horiz--sm" href="/blog/tags/go">go</a></div><div class="col margin-top--sm"><a href="https://github.com/centrifugal/centrifugal.dev/edit/main/blog/2020-11-12-scaling-websocket.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/2021/01/15/centrifuge-intro"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Â« Centrifuge â€“ real-time messaging with Go</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/2020/10/16/experimenting-with-quic-transport"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Experimenting with QUIC and WebTransport Â»</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#websocket-server-tasks" class="table-of-contents__link">WebSocket server tasks</a></li><li><a href="#websocket-libraries" class="table-of-contents__link">WebSocket libraries</a></li><li><a href="#os-tuning" class="table-of-contents__link">OS tuning</a></li><li><a href="#sending-many-messages" class="table-of-contents__link">Sending many messages</a></li><li><a href="#websocket-fallback-transport" class="table-of-contents__link">WebSocket fallback transport</a></li><li><a href="#performance-is-not-scalability" class="table-of-contents__link">Performance is not scalability</a></li><li><a href="#massive-reconnect" class="table-of-contents__link">Massive reconnect</a></li><li><a href="#message-event-stream-benefits" class="table-of-contents__link">Message event stream benefits</a></li><li><a href="#conclusion" class="table-of-contents__link">Conclusion</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Contacts</div><ul class="footer__items"><li class="footer__item"><a href="mailto:centrifugal.dev@gmail.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Send e-mail</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/centrifugal/centrifugo/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Issues<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://t.me/joinchat/U57MI8Lam9mhpuhd" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Telegram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://discord.gg/tYgADKx" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/attributions">Attributions</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2021 Centrifugal.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.55faadf6.js"></script>
<script src="/assets/js/main.b54f4b3e.js"></script>
</body>
</html>